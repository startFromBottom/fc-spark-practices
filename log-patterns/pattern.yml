name: Apache General Access
# file: /Users/eomhyeonho/Workspace/spark-practice/2_rdd_examples/data/log.txt # update to your path (for rdd example
file: /Users/eomhyeonho/Workspace/spark-practices/3_sparksql_examples/data/log.csv # update to your path (for sparksql example)
#format: "{log_ip} | [{log_time}] | \"{log_method} {log_path} HTTP/1.1\" | {log_status}" # for rdd example
format: "{log_ip},{log_time},{log_method},{log_path},{log_status},{latency}" # for spark sql example
frequency:
  seconds: 0.5
offset:
  seconds: 0
jitter:
  seconds: 5
amount: 20
fields:
  log_ip:
    type: ip
  log_time:
    type: timestamp
#    format: "%d/%b/%Y:%H:%M:%S" # for rdd examples
    format: "%Y-%m-%d %H:%M:%S" # for sparksql examples
  log_method:
    type: enum
    values: [POST, GET, PUT, PATCH, DELETE]
  log_path:
    type: enum
    values:
      - /auth
      - /alerts
      - /events
      - /playbooks
      - /lists
      - /fieldsets
      - /customers
      - /collectors
      - /parsers
      - /users
  log_status:
    type: enum
    values: [200, 201, 204, 300, 301, 400, 401, 403, 404, 500, 503]
  log_bytes:
    type: integer
    min: 2000
    max: 5000
  latency:
    type: integer
    min: 1
    max: 100